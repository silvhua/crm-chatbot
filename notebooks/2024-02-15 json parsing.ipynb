{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "sys.path.append(r'/home/silvhua/repositories/GHL-chat/src/')\n",
    "sys.path.append(r'/home/silvhua/repositories/GHL-chat/src/app')\n",
    "from silvhua import *\n",
    "from chat_functions import *\n",
    "from langchain.agents import Tool\n",
    "from data_functions import parse_json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.ghl_requests import *\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../src/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-4\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-vision-preview\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n"
     ]
    }
   ],
   "source": [
    "models_list = openai_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/silvhua/repositories/GHL-chat/src/app/private'\n",
    "contacts = load_json('contacts.json', path)\n",
    "contactId = contacts['me_fb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_dict = dict()\n",
    "conversation_dict = dict()\n",
    "reply_dict = dict()\n",
    "conversation_id = 1\n",
    "question_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "inbound_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens retrieved from S3 for CoachMcloone.\n",
      "Tokens saved to S3 CoachMcloone.\n"
     ]
    }
   ],
   "source": [
    "from app.ghl_requests import *\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../src/.env')\n",
    "response = refresh_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copied from 2024-02-04 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_system_message():\n",
    "    system_message = f\"\"\"\n",
    "You work for an online personal training business. \n",
    "Your role is to reach out to leads and book qualified leads for a call to see if they are a good fit \n",
    "for the business's online coaching program.\n",
    "If the contact provides their telephone number, extract that phone number.\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "- \"phone_number\" (string or None): The phone number of the contact, if available.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    return system_message\n",
    "\n",
    "def test_chatbot(contactId, InboundMessage, tools):\n",
    "    system_message_dict[conversation_id] = create_test_system_message()\n",
    "    conversation_dict[conversation_id] = create_chatbot(\n",
    "        contactId, system_message_dict[conversation_id], tools=tools,\n",
    "        # model='gpt-4-32k'\n",
    "        )\n",
    "\n",
    "    reply_dict[conversation_id][question_id] = chat_with_chatbot(\n",
    "        InboundMessage, conversation_dict[conversation_id]\n",
    "    )\n",
    "    chatbot_response = parse_json_string(reply_dict[conversation_id][question_id][\"output\"])\n",
    "\n",
    "    return chatbot_response\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=f\"placeholder_function\",\n",
    "        func=placeholder_function,\n",
    "        description=f\"This function does not do anything.\",\n",
    "    )\n",
    "]\n",
    "InboundMessage = 'My number is 7788917189'\n",
    "conversation_id = 1\n",
    "question_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "chatbot_response = test_chatbot(contactId, InboundMessage, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 2024-02-10 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_system_message(\n",
    "        business_name='CoachMcloone', \n",
    "        prompts_filepath='/home/silvhua/repositories/GHL-chat/src/app/private/prompts',\n",
    "        examples_filepath='/home/silvhua/repositories/GHL-chat/src/app/private/data/chat_examples', \n",
    "        doc_filepath='/home/silvhua/repositories/GHL-chat/src/app/private/data/rag_docs'\n",
    "        ):\n",
    "    instructions_filename = f'{business_name}.md'\n",
    "    examples_filename = f'{business_name}.txt'\n",
    "    document_filename = f'{business_name}_doc.md'\n",
    "    try:\n",
    "        instructions = load_txt(instructions_filename, prompts_filepath)\n",
    "        examples = load_txt(examples_filename, examples_filepath)\n",
    "        document = load_txt(document_filename, doc_filepath)\n",
    "    except Exception as error:\n",
    "        if cloud == True:\n",
    "            print(f'Error: {error}')\n",
    "            print('Loading prompt files from s3...')\n",
    "        s3 = boto3.client('s3')\n",
    "        instructions = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=instructions_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "        examples = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=examples_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "        document = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=document_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "    # print(f'**Instructions component of system message**: \\n{instructions}\\n')\n",
    "\n",
    "    system_message = f\"\"\"{instructions}\n",
    "\n",
    "## Other Messages\n",
    "\n",
    "Only repond to inbound messages that can be answered by the message templates or provided \n",
    "documenation. Otherwise, return \"[ALERT HUMAN]\". \n",
    "If the message indicates the contact has an eating disorder, suicidal ideation, or other serious mental health \n",
    "conditions, return \"[ALERT HUMAN]\". \n",
    "The \"[ALERT HUMAN]\" message will trigger a human staff member to review the messages to write a response. \n",
    "It is better to err on the side of caution and flag a staff rather than give a wrong response.\n",
    "    \n",
    "# Stage 1\n",
    "\n",
    "Determine if you should generate a response to the inbound message. If so, generate the response and proceed \n",
    "to Stage 2. Otherwise, return \"[ALERT HUMAN]\".\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "- \"phone_number\" (string or None): The phone number of the contact, if available.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Below are example conversations with leads. Each lead as a unique contact ID.\n",
    "An InboundMessage is from the lead. An OutboundMessage is from you.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## Relevant documentation\n",
    "\n",
    "{document}\n",
    "\n",
    "# Stage 2\n",
    "\n",
    "Review your response from stage 1. \n",
    "Revise your response if needed to make sure you followed the instructions.\n",
    "Revise your response if needed to avoid asking questions that have already been answered in previous messages.\n",
    "Make sure that if the question cannot be answered through the message templates or documentation, \n",
    "you return \"[ALERT HUMAN]\".\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "Review your response from stage 2 to revise as needed to make it concise.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    ###\n",
    "    # print(f'\\n**System_message**: {system_message}\\n\\n')\n",
    "    return system_message\n",
    "\n",
    "def test_chatbot(contactId, InboundMessage, tools):\n",
    "    system_message_dict[conversation_id] = create_test_system_message()\n",
    "    conversation_dict[conversation_id] = create_chatbot(\n",
    "        contactId, system_message_dict[conversation_id], tools=tools,\n",
    "        # model='gpt-4-32k'\n",
    "        )\n",
    "\n",
    "    reply_dict[conversation_id][question_id] = chat_with_chatbot(\n",
    "        InboundMessage, conversation_dict[conversation_id]\n",
    "    )\n",
    "    chatbot_response = parse_json_string(reply_dict[conversation_id][question_id][\"output\"])\n",
    "\n",
    "    return chatbot_response\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=f\"placeholder_function\",\n",
    "        func=placeholder_function,\n",
    "        description=f\"This function does not do anything.\",\n",
    "    )\n",
    "]\n",
    "inbound_id = 1\n",
    "inbound_dict[inbound_id] = 'hi'\n",
    "conversation_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "chatbot_response = test_chatbot(contactId, inbound_dict[inbound_id], tools)\n",
    "chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ghl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
