{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "sys.path.append(r'/home/silvhua/repositories/GHL-chat/src/')\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "import boto3\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Create memory \n",
    "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "def create_system_message(\n",
    "        business_name, \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        ):\n",
    "    instructions_filename = f'{business_name}.md'\n",
    "    try:\n",
    "        instructions = load_txt(instructions_filename, prompts_filepath)\n",
    "        # examples = load_txt(f'{business_name}.txt', examples_filepath)\n",
    "        # document = load_txt(f'{business_name}_doc.md', doc_filepath)\n",
    "    except:\n",
    "        s3 = boto3.client('s3')\n",
    "        instructions = s3.get_object(Bucket='ownitfit-silvhua', Key=instructions_filename)\n",
    "    return instructions\n",
    "\n",
    "    system_message = f\"\"\"{instructions}\n",
    "\n",
    "## Other Messages\n",
    "\n",
    "Only repond to inbound messages that can be answered by the message templates or provided \n",
    "documenation. Otherwise, return \"[ALERT HUMAN]\". \n",
    "The \"[ALERT HUMAN]\" message will trigger a human staff member to review the messages to write a response. \n",
    "It is better to err on the side of caution and flag a staff rather than give a wrong response.\n",
    "    \n",
    "# Stage 1\n",
    "\n",
    "Determine if you should generate a response to the inbound message. If so, generate the response and proceed \n",
    "to Stage 2. Otherwise, return \"[ALERT HUMAN]\".\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Below are example conversations with leads. Each lead as a unique contact ID.\n",
    "An InboundMessage is from the lead. An OutboundMessage is from you.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## Relevant documentation\n",
    "\n",
    "{document}\n",
    "\n",
    "# Stage 2\n",
    "\n",
    "Review your response from stage 1. \n",
    "Revise your response if needed to make sure you followed the instructions.\n",
    "Make sure that if the question cannot be answered through the message templates or documentation, \n",
    "you return \"[ALERT HUMAN]\".\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "Review your response from stage 2 to revise as needed to make it concise.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    return system_message\n",
    "\n",
    "iteration = 1\n",
    "result_dict[iteration] = create_system_message(\n",
    "        'CoachMcloone', \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the s3 object\n",
    "print(result_dict[iteration]['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[iteration]['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1.01\n",
    "result_dict[iteration] = create_system_message(\n",
    "        'Coach', \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        )\n",
    "result_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1.02\n",
    "result_dict[iteration] = create_system_message(\n",
    "        'CoachMcloone', \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        )\n",
    "result_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "import boto3\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Create memory \n",
    "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "def create_system_message(\n",
    "        business_name, \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        ):\n",
    "    instructions_filename = f'{business_name}.md'\n",
    "    try:\n",
    "        instructions = load_txt(instructions_filename, prompts_filepath)\n",
    "        # examples = load_txt(f'{business_name}.txt', examples_filepath)\n",
    "        # document = load_txt(f'{business_name}_doc.md', doc_filepath)\n",
    "    except:\n",
    "        s3 = boto3.client('s3')\n",
    "        instructions = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=instructions_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "    return instructions\n",
    "\n",
    "    system_message = f\"\"\"{instructions}\n",
    "\n",
    "## Other Messages\n",
    "\n",
    "Only repond to inbound messages that can be answered by the message templates or provided \n",
    "documenation. Otherwise, return \"[ALERT HUMAN]\". \n",
    "The \"[ALERT HUMAN]\" message will trigger a human staff member to review the messages to write a response. \n",
    "It is better to err on the side of caution and flag a staff rather than give a wrong response.\n",
    "    \n",
    "# Stage 1\n",
    "\n",
    "Determine if you should generate a response to the inbound message. If so, generate the response and proceed \n",
    "to Stage 2. Otherwise, return \"[ALERT HUMAN]\".\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Below are example conversations with leads. Each lead as a unique contact ID.\n",
    "An InboundMessage is from the lead. An OutboundMessage is from you.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## Relevant documentation\n",
    "\n",
    "{document}\n",
    "\n",
    "# Stage 2\n",
    "\n",
    "Review your response from stage 1. \n",
    "Revise your response if needed to make sure you followed the instructions.\n",
    "Make sure that if the question cannot be answered through the message templates or documentation, \n",
    "you return \"[ALERT HUMAN]\".\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "Review your response from stage 2 to revise as needed to make it concise.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    return system_message\n",
    "\n",
    "iteration = 1.1\n",
    "result_dict[iteration] = create_system_message(\n",
    "        'CoachMcloone', \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        )\n",
    "result_dict[iteration] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "import boto3\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Create memory \n",
    "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "def create_system_message(\n",
    "        business_name, \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        ):\n",
    "    instructions_filename = f'{business_name}.md'\n",
    "    examples_filename = f'{business_name}.txt'\n",
    "    document_filename = f'{business_name}_doc.md'\n",
    "    try:\n",
    "        instructions = load_txt(instructions_filename, prompts_filepath)\n",
    "        examples = load_txt(examples_filename, examples_filepath)\n",
    "        document = load_txt(document_filename, doc_filepath)\n",
    "    except:\n",
    "        s3 = boto3.client('s3')\n",
    "        instructions = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=instructions_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "        examples = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=examples_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "        document = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=document_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "\n",
    "    system_message = f\"\"\"{instructions}\n",
    "\n",
    "## Other Messages\n",
    "\n",
    "Only repond to inbound messages that can be answered by the message templates or provided \n",
    "documenation. Otherwise, return \"[ALERT HUMAN]\". \n",
    "The \"[ALERT HUMAN]\" message will trigger a human staff member to review the messages to write a response. \n",
    "It is better to err on the side of caution and flag a staff rather than give a wrong response.\n",
    "    \n",
    "# Stage 1\n",
    "\n",
    "Determine if you should generate a response to the inbound message. If so, generate the response and proceed \n",
    "to Stage 2. Otherwise, return \"[ALERT HUMAN]\".\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Below are example conversations with leads. Each lead as a unique contact ID.\n",
    "An InboundMessage is from the lead. An OutboundMessage is from you.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## Relevant documentation\n",
    "\n",
    "{document}\n",
    "\n",
    "# Stage 2\n",
    "\n",
    "Review your response from stage 1. \n",
    "Revise your response if needed to make sure you followed the instructions.\n",
    "Make sure that if the question cannot be answered through the message templates or documentation, \n",
    "you return \"[ALERT HUMAN]\".\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "Review your response from stage 2 to revise as needed to make it concise.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    return system_message\n",
    "\n",
    "iteration = 1.11\n",
    "result_dict[iteration] = create_system_message(\n",
    "        'CoachMcloone', \n",
    "        prompts_filepath='app/private/prompts',\n",
    "        examples_filepath='app/private/data/chat_examples', doc_filepath='app/private/data/rag_docs'\n",
    "        )\n",
    "result_dict[iteration] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_dict[iteration] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter out emplated emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "event = {\n",
    "  \"body\": {\n",
    "    \"type\": \"OutboundMessage\",\n",
    "    \"locationId\": \"fsdVH26v30hoBBQOBttG\",\n",
    "    \"attachments\": [],\n",
    "    \"body\": \"This is a sample email. click here to unsubscribe. Link.\",\n",
    "    \"contactId\": \"6kIAuqeiBUxJ3nWTwNVE\",\n",
    "    \"contentType\": \"text/plain\",\n",
    "    \"conversationId\": \"fcanlLgpbQgQhderivVs\",\n",
    "    \"dateAdded\": \"2024-01-13T05:15:00.000Z\",\n",
    "    \"direction\": \"outbound\",\n",
    "    \"messageType\": \"Email\",\n",
    "    \"userId\": \"80pzXdC3MCqKRpzrteuj\"\n",
    "  },\n",
    "  \"direct_local_invoke\": 1\n",
    "}\n",
    "payload = event[\"body\"]\n",
    "message = payload.get(\"body\")\n",
    "# see if message contains the substring \"unsubscribe\"\n",
    "if \"click here to unsubscribe\" in message.lower():\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ghl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
