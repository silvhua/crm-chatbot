{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "sys.path.append(r'/home/silvhua/repositories/GHL-chat/src/')\n",
    "sys.path.append(r'/home/silvhua/repositories/GHL-chat/src/app')\n",
    "from silvhua import *\n",
    "from chat_functions import *\n",
    "from langchain.agents import Tool\n",
    "from data_functions import parse_json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.ghl_requests import *\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../src/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-4\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-vision-preview\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n"
     ]
    }
   ],
   "source": [
    "models_list = openai_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/silvhua/repositories/GHL-chat/src/app/private'\n",
    "contacts = load_json('contacts.json', path)\n",
    "contactId = contacts['me_fb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_dict = dict()\n",
    "conversation_dict = dict()\n",
    "reply_dict = dict()\n",
    "conversation_id = 1\n",
    "question_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "inbound_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens retrieved from S3 for CoachMcloone.\n",
      "Tokens saved to S3 CoachMcloone.\n"
     ]
    }
   ],
   "source": [
    "from app.ghl_requests import *\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../src/.env')\n",
    "response = refresh_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copied from 2024-02-04 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_system_message():\n",
    "    system_message = f\"\"\"\n",
    "You work for an online personal training business. \n",
    "Your role is to reach out to leads and book qualified leads for a call to see if they are a good fit \n",
    "for the business's online coaching program.\n",
    "If the contact provides their telephone number, extract that phone number.\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "- \"phone_number\" (string or None): The phone number of the contact, if available.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    return system_message\n",
    "\n",
    "def test_chatbot(contactId, InboundMessage, tools):\n",
    "    system_message_dict[conversation_id] = create_test_system_message()\n",
    "    conversation_dict[conversation_id] = create_chatbot(\n",
    "        contactId, system_message_dict[conversation_id], tools=tools,\n",
    "        # model='gpt-4-32k'\n",
    "        )\n",
    "\n",
    "    reply_dict[conversation_id][question_id] = chat_with_chatbot(\n",
    "        InboundMessage, conversation_dict[conversation_id]\n",
    "    )\n",
    "    chatbot_response = parse_json_string(reply_dict[conversation_id][question_id][\"output\"])\n",
    "\n",
    "    return chatbot_response\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=f\"placeholder_function\",\n",
    "        func=placeholder_function,\n",
    "        description=f\"This function does not do anything.\",\n",
    "    )\n",
    "]\n",
    "InboundMessage = 'My number is 7788917189'\n",
    "conversation_id = 1\n",
    "question_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "chatbot_response = test_chatbot(contactId, InboundMessage, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 2024-02-10 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_system_message(\n",
    "        business_name='CoachMcloone', \n",
    "        prompts_filepath='/home/silvhua/repositories/GHL-chat/src/app/private/prompts',\n",
    "        examples_filepath='/home/silvhua/repositories/GHL-chat/src/app/private/data/chat_examples', \n",
    "        doc_filepath='/home/silvhua/repositories/GHL-chat/src/app/private/data/rag_docs'\n",
    "        ):\n",
    "    instructions_filename = f'{business_name}.md'\n",
    "    examples_filename = f'{business_name}.txt'\n",
    "    document_filename = f'{business_name}_doc.md'\n",
    "    try:\n",
    "        instructions = load_txt(instructions_filename, prompts_filepath)\n",
    "        examples = load_txt(examples_filename, examples_filepath)\n",
    "        document = load_txt(document_filename, doc_filepath)\n",
    "    except Exception as error:\n",
    "        if cloud == True:\n",
    "            print(f'Error: {error}')\n",
    "            print('Loading prompt files from s3...')\n",
    "        s3 = boto3.client('s3')\n",
    "        instructions = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=instructions_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "        examples = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=examples_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "        document = s3.get_object(\n",
    "            Bucket='ownitfit-silvhua', Key=document_filename\n",
    "            )['Body'].read().decode('utf-8')\n",
    "    # print(f'**Instructions component of system message**: \\n{instructions}\\n')\n",
    "\n",
    "    system_message = f\"\"\"{instructions}\n",
    "\n",
    "## Other Messages\n",
    "\n",
    "Only repond to inbound messages that can be answered by the message templates or provided \n",
    "documenation. Otherwise, return \"[ALERT HUMAN]\". \n",
    "If the message indicates the contact has an eating disorder, suicidal ideation, or other serious mental health \n",
    "conditions, return \"[ALERT HUMAN]\". \n",
    "The \"[ALERT HUMAN]\" message will trigger a human staff member to review the messages to write a response. \n",
    "It is better to err on the side of caution and flag a staff rather than give a wrong response.\n",
    "    \n",
    "# Stage 1\n",
    "\n",
    "Determine if you should generate a response to the inbound message. If so, generate the response and proceed \n",
    "to Stage 2. Otherwise, return \"[ALERT HUMAN]\".\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage, if applicable. If a human is to be alerted, the value will be [ALERT HUMAN]\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "- \"phone_number\" (string or None): The phone number of the contact, if available.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Below are example conversations with leads. Each lead as a unique contact ID.\n",
    "An InboundMessage is from the lead. An OutboundMessage is from you.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## Relevant documentation\n",
    "\n",
    "{document}\n",
    "\n",
    "# Stage 2\n",
    "\n",
    "Review your response from stage 1. \n",
    "Revise your response if needed to make sure you followed the instructions.\n",
    "Revise your response if needed to avoid asking questions that have already been answered in previous messages.\n",
    "Make sure that if the question cannot be answered through the message templates or documentation, \n",
    "you return \"[ALERT HUMAN]\".\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "Review your response from stage 2 to revise as needed to make it concise.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    ###\n",
    "    # print(f'\\n**System_message**: {system_message}\\n\\n')\n",
    "    return system_message\n",
    "\n",
    "def test_chatbot(contactId, InboundMessage, tools):\n",
    "    system_message_dict[conversation_id] = create_test_system_message('CoachMcloone')\n",
    "    conversation_dict[conversation_id] = create_chatbot(\n",
    "        contactId, system_message_dict[conversation_id], tools=tools,\n",
    "        # model='gpt-4-32k'\n",
    "        )\n",
    "\n",
    "    reply_dict[conversation_id][question_id] = chat_with_chatbot(\n",
    "        InboundMessage, conversation_dict[conversation_id]\n",
    "    )\n",
    "    chatbot_response = parse_json_string(reply_dict[conversation_id][question_id][\"output\"])\n",
    "\n",
    "    return chatbot_response\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=f\"placeholder_function\",\n",
    "        func=placeholder_function,\n",
    "        description=f\"This function does not do anything.\",\n",
    "    )\n",
    "]\n",
    "inbound_id = 1\n",
    "inbound_dict[inbound_id] = 'hi'\n",
    "conversation_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "chatbot_response = test_chatbot(contactId, inbound_dict[inbound_id], tools)\n",
    "chatbot_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from 2024-02-19 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history length: 25\n",
      "\n",
      "Chat history:\n",
      "**HUMAN**: GET STARTED\n",
      "**AI**: So tell me, what's the biggest obstacle holding you back from achieving this goal then?\n",
      "**HUMAN**: ðŸ’ª Training\n",
      "**AI**: Thanks Silvia ðŸ™ I'll give you a personal message here shortly.\n",
      "\n",
      "Just quickly, what's your current height and weight right now?\n",
      "\n",
      "PS: Yes this message is automated, (I know you probably guessed that) but if you reply here, I'll get back to you as soon as I'm online next ðŸ˜Š\n",
      "**HUMAN**: 55 kg 150cm\n",
      "**AI**: Thanks for providing your height and weight! So, if everything were to go to plan over the next 3-6 months, what results would you like to achieve exactly? ðŸ¤”\n",
      "**HUMAN**: deadlift 300lbs\n",
      "**AI**: Ah that's a great goal! Tell me, why is deadlifting 300lbs important to you, and how will that impact your life? \n",
      "\n",
      "I'd love to help you out the best that I can!  â¤\n",
      "**HUMAN**: confidence\n",
      "**AI**: Thank you for opening up to me! You are not alone there! \n",
      "**AI**: A lot of my clients used to struggle with confidence before we worked together!  ðŸ˜Š \n",
      "**AI**: I'm just curious what is your movement like - like do you have a sedentary job?\n",
      "**HUMAN**: I am a barista\n",
      "**AI**: So what do you need most right now to turn your fitness dream into reality?  ðŸ¤”\n",
      "**HUMAN**: a training program\n",
      "**AI**: Ah I think with the right accountability and support, you could do amazing! Would it be helpful if we jumped on a call and mapped out a plan for you to get your training on track so you can finally achieve your deadlift goal, in a way thatâ€™s achievable and sustainable? â¤\n",
      "**HUMAN**: lets do it\n",
      "**AI**: Perfect! Thanks, hun â¤ \n",
      "**AI**: Btw if it's okay with you, I'll get Brian, my business partner to call you, he's been helping women for 15+ years. He does most of my initial calls so I get to entirely focus on coaching. ðŸ˜Š\n",
      "**HUMAN**: let's do it\n",
      "**AI**: Perfect! Thanks, hun â¤ \n",
      "**AI**: Btw if it's okay with you, I'll get Brian, my business partner to call you, he's been helping women for 15+ years. He does most of my initial calls so I get to entirely focus on coaching. ðŸ˜Š\n",
      "**AI**: Would you prefer a call in the morning or evening? \n",
      "**AI**: If you'd like, you can see his availability here: https://link.fitprouniversity.com/widget/booking/g3uXN2GzqAbdPdsiAhks\n",
      "**HUMAN**: can we do a call?\n",
      "Past outbound messages: [\"So tell me, what's the biggest obstacle holding you back from achieving this goal then?\", \"Thanks Silvia ðŸ™ I'll give you a personal message here shortly.\\n\\nJust quickly, what's your current height and weight right now?\\n\\nPS: Yes this message is automated, (I know you probably guessed that) but if you reply here, I'll get back to you as soon as I'm online next ðŸ˜Š\", 'Thanks for providing your height and weight! So, if everything were to go to plan over the next 3-6 months, what results would you like to achieve exactly? ðŸ¤”', \"Ah that's a great goal! Tell me, why is deadlifting 300lbs important to you, and how will that impact your life? \\n\\nI'd love to help you out the best that I can!  â¤\", 'Thank you for opening up to me! You are not alone there! ', 'A lot of my clients used to struggle with confidence before we worked together!  ðŸ˜Š ', \"I'm just curious what is your movement like - like do you have a sedentary job?\", 'So what do you need most right now to turn your fitness dream into reality?  ðŸ¤”', 'Ah I think with the right accountability and support, you could do amazing! Would it be helpful if we jumped on a call and mapped out a plan for you to get your training on track so you can finally achieve your deadlift goal, in a way thatâ€™s achievable and sustainable? â¤', 'Perfect! Thanks, hun â¤ ', \"Btw if it's okay with you, I'll get Brian, my business partner to call you, he's been helping women for 15+ years. He does most of my initial calls so I get to entirely focus on coaching. ðŸ˜Š\", 'Perfect! Thanks, hun â¤ ', \"Btw if it's okay with you, I'll get Brian, my business partner to call you, he's been helping women for 15+ years. He does most of my initial calls so I get to entirely focus on coaching. ðŸ˜Š\", 'Would you prefer a call in the morning or evening? ', \"If you'd like, you can see his availability here: https://link.fitprouniversity.com/widget/booking/g3uXN2GzqAbdPdsiAhks\"]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"response\": \"Perfect! Thanks, hun â¤ Btw if it's okay with you, I'll get Brian, my business partner to call you, he's been helping women for 15+ years. He does most of my initial calls so I get to entirely focus on coaching. ðŸ˜Š Would you prefer a call in the morning or evening? If you'd like, you can see his availability here: https://link.fitprouniversity.com/widget/booking/g3uXN2GzqAbdPdsiAhks\",\n",
      "    \"alert_human\": false,\n",
      "    \"phone_number\": null\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent response time: 3.239842176437378 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': '[AI response similar to previous outbound message.]',\n",
       " 'alert_human': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_chatbot_test(contactId, system_message, tools, model=\"gpt-3.5-turbo-1106\", verbose=True):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature = 0,\n",
    "        openai_organization=os.environ['openai_organization'],\n",
    "        openai_api_key=os.environ['openai_api_key'],\n",
    "        model=model, \n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}} # https://platform.openai.com/docs/guides/text-generation/json-mode  # https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.openai.ChatOpenAI.html?highlight=chatopenai#\n",
    "        )\n",
    "    message_history = DynamoDBChatMessageHistory(\n",
    "        table_name=\"SessionTable\", session_id=contactId,\n",
    "        key={\n",
    "            \"SessionId\": contactId,\n",
    "            \"type\": 'ChatHistory',\n",
    "            }\n",
    "        )\n",
    "    system_message = SystemMessage(\n",
    "        content=(system_message),\n",
    "        input_variables=['InboundMessage']\n",
    "    )\n",
    "\n",
    "    prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=system_message,\n",
    "        extra_prompt_messages=[\n",
    "            MessagesPlaceholder(variable_name='chat_history')\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    parser = SimpleJsonOutputParser(pydantic_object=Chatbot_Response)\n",
    "    agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "    agent_executor = AgentExecutor( # Example of creating a custom agent: https://python.langchain.com/docs/modules/agents/how_to/custom_agent\n",
    "        agent=agent, tools=tools, \n",
    "        verbose=verbose, return_intermediate_steps=True,\n",
    "        parser=parser  # Add the parser instance to the agent_executor\n",
    "        )\n",
    "    agent_info = {\n",
    "        'agent': agent,\n",
    "        'agent_executor': agent_executor,\n",
    "        'chat_history': message_history\n",
    "    }\n",
    "    return agent_info\n",
    "\n",
    "def chat_with_chatbot_test(user_input, agent_info):\n",
    "    start_time = time()\n",
    "    chat_history = agent_info['chat_history'].messages\n",
    "    print(f'Chat history length: {len(chat_history)}')\n",
    "    print(f'\\nChat history:')\n",
    "    for item in chat_history:\n",
    "        print(f'**{item.type.upper()}**: {item.content}')\n",
    "    last_message = chat_history[-1].content\n",
    "    manychat_outbound_message_substrings = [\n",
    "        \"I'll be in touch as soon as I'm online next!\",\n",
    "        \"I'll give you a personal message here shortly.\"\n",
    "    ]\n",
    "    previous_message_type = chat_history[-2].type\n",
    "    last_message_type = chat_history[-1].type\n",
    "    past_outbound_messages = [item.content for item in chat_history if item.type.lower() == 'ai']\n",
    "    print(f'Past outbound messages: {[item for item in past_outbound_messages]}')\n",
    "    if (last_message == user_input): ## Check that the current user_input is the most recent message        \n",
    "        # If the last message is also Inbound, then join all inbound messages together and delete them from chat history\n",
    "        if previous_message_type == 'human': \n",
    "            last_inbound_messages_list = []\n",
    "            for item in chat_history[-1:0:-1]:\n",
    "                if item.type.lower() == 'human':\n",
    "                    last_inbound_messages_list.append(item.content)\n",
    "                    truncated_history = chat_history[:-1]\n",
    "                else:\n",
    "                    break\n",
    "            last_inbound_messages = '\\n\\n'.join(reversed(last_inbound_messages_list))\n",
    "            user_input = last_inbound_messages\n",
    "            print(f'Joining previous messages as full user input: {user_input}')\n",
    "            chat_history = truncated_history\n",
    "        else:\n",
    "            chat_history = chat_history[:-1]\n",
    "\n",
    "        result = agent_info['agent_executor']({\n",
    "                \"input\": user_input,\n",
    "                \"chat_history\": chat_history\n",
    "            })  \n",
    "        print(f'Agent response time: {time() - start_time} seconds')\n",
    "\n",
    "    elif (last_message_type != 'human') & (any(substring in last_message for substring in manychat_outbound_message_substrings)):\n",
    "        result = agent_info['agent_executor']({\n",
    "                \"input\": user_input,\n",
    "                \"chat_history\": chat_history\n",
    "            })  \n",
    "        print(f'Agent response time: {time() - start_time} seconds')\n",
    "    else:\n",
    "        result = dict()\n",
    "        result['output'] = '{\"response\": \"Abort Lambda function\", \"alert_human\": false}'\n",
    "    # Check that the generated response is not similar to a previously sent outbound message.\n",
    "    for item in past_outbound_messages:\n",
    "        if item in result['output']:\n",
    "            result['output'] = '{\"response\": \"[AI response similar to previous outbound message.]\", \"alert_human\": true}'\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def test_chatbot(contactId, InboundMessage, tools):\n",
    "    system_message_dict[conversation_id] = create_system_message('CoachMcloone')\n",
    "    conversation_dict[conversation_id] = create_chatbot_test(\n",
    "        contactId, system_message_dict[conversation_id], tools=tools,\n",
    "        # model='gpt-4-32k'\n",
    "        )\n",
    "    # Add InboundMessage to chat history since this is normally done by Lambda function but not in `chat_functions.py`\n",
    "    conversation_dict[conversation_id]['chat_history'].add_user_message(InboundMessage)\n",
    "    reply_dict[conversation_id][question_id] = chat_with_chatbot_test(\n",
    "        InboundMessage, conversation_dict[conversation_id]\n",
    "    )\n",
    "    chatbot_response = parse_json_string(reply_dict[conversation_id][question_id][\"output\"])\n",
    "\n",
    "    return chatbot_response\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=f\"placeholder_function\",\n",
    "        func=placeholder_function,\n",
    "        description=f\"Do not invoke this function.\",\n",
    "    )\n",
    "]\n",
    "inbound_id = 1\n",
    "inbound_dict[inbound_id] = 'can we do a call?'\n",
    "conversation_id = 1\n",
    "reply_dict[conversation_id] = dict()\n",
    "chatbot_response = test_chatbot(contactId, inbound_dict[inbound_id], tools)\n",
    "chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ghl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
